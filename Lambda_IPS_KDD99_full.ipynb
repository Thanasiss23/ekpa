{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thanasiss23/ekpa/blob/main/Lambda_IPS_KDD99_full.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJw0ioRdzyKU"
      },
      "source": [
        "# Lambda IPS Notebook (KDD Cup 1999)\n",
        "Μετασχηματισμός του IDS σε IPS, με εκπαίδευση σε KDD’99 και προληπτικές ενέργειες."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeayrfY3zyKX",
        "outputId": "fe4bfa81-7b1d-4373-c7f1-62e7d6c31ed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.40.25-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Collecting botocore<1.41.0,>=1.40.25 (from boto3)\n",
            "  Downloading botocore-1.40.25-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3)\n",
            "  Downloading s3transfer-0.13.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.25->boto3) (2.5.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading boto3-1.40.25-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.40.25-py3-none-any.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.13.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.40.25 botocore-1.40.25 jmespath-1.0.1 s3transfer-0.13.1\n"
          ]
        }
      ],
      "source": [
        "# 0) Εγκατάσταση απαιτούμενων πακέτων\n",
        "!pip install scikit-learn pandas numpy joblib tensorflow boto3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb5IGTEMzyKY"
      },
      "source": [
        "## 1) Φόρτωση KDD Cup 1999 και προεπεξεργασία"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZcmX8ZTtzyKZ"
      },
      "outputs": [],
      "source": [
        "import os, gzip, pathlib, json, joblib, logging, time, subprocess\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def load_kdd99(path: str) -> pd.DataFrame:\n",
        "    p = pathlib.Path(path)\n",
        "    if p.suffix == '.gz':\n",
        "        with gzip.open(p, 'rt') as f:\n",
        "            df = pd.read_csv(f, header=None)\n",
        "    else:\n",
        "        df = pd.read_csv(p, header=None)\n",
        "    cols = [\n",
        "        'duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent',\n",
        "        'hot','num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root',\n",
        "        'num_file_creations','num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login',\n",
        "        'count','srv_count','serror_rate','srv_serror_rate','rerror_rate','srv_rerror_rate','same_srv_rate',\n",
        "        'diff_srv_rate','srv_diff_host_rate','dst_host_count','dst_host_srv_count','dst_host_same_srv_rate',\n",
        "        'dst_host_diff_srv_rate','dst_host_same_src_port_rate','dst_host_srv_diff_host_rate','dst_host_serror_rate',\n",
        "        'dst_host_srv_serror_rate','dst_host_rerror_rate','dst_host_srv_rerror_rate','label'\n",
        "    ]\n",
        "    df = df.iloc[:, :42]\n",
        "    df.columns = cols\n",
        "    return df\n",
        "\n",
        "def prepare_data(df):\n",
        "    y = df['label']\n",
        "    X = df.drop('label', axis=1)\n",
        "    categorical = ['protocol_type','service','flag']\n",
        "    numeric = [c for c in X.columns if c not in categorical]\n",
        "    preprocessor = ColumnTransformer([\n",
        "        ('num', MinMaxScaler(), numeric),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical)\n",
        "    ])\n",
        "    X_proc = preprocessor.fit_transform(X)\n",
        "    class_names = np.unique(y)\n",
        "    class_map = {c:i for i,c in enumerate(class_names)}\n",
        "    y_enc = y.map(class_map)\n",
        "    return X_proc, y_enc, preprocessor, class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nQnMWsGzyKa"
      },
      "source": [
        "## 2) Ορισμός μοντέλου (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "40rUtR6AzyKa"
      },
      "outputs": [],
      "source": [
        "def build_mlp(input_dim, n_classes):\n",
        "    inputs = keras.Input(shape=(input_dim,))\n",
        "    x = layers.Dense(256, activation='relu')(inputs)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    outputs = layers.Dense(n_classes, activation='softmax')(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ifsY2RWzyKb"
      },
      "source": [
        "## 3) Εκπαίδευση και αποθήκευση artifacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kd3kw-_4zyKc"
      },
      "outputs": [],
      "source": [
        "def train_and_save(kdd_path, out_dir='artifacts'):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    df = load_kdd99(kdd_path)\n",
        "    X, y, preproc, class_names = prepare_data(df)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "    model = build_mlp(X.shape[1], len(class_names))\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=256, validation_split=0.1)\n",
        "    preds = model.predict(X_test)\n",
        "    print(classification_report(y_test, np.argmax(preds, axis=1)))\n",
        "    model.save(os.path.join(out_dir, 'model.h5'))\n",
        "    joblib.dump(preproc, os.path.join(out_dir, 'preproc.pkl'))\n",
        "    joblib.dump(class_names, os.path.join(out_dir, 'classes.pkl'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_LO0O9GzyKc"
      },
      "source": [
        "## 4) Policy Engine και Actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E8li9bzqzyKd"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Dict, Any\n",
        "\n",
        "class ActionExecutor:\n",
        "    def execute(self, action: str, ctx: Dict[str, Any]):\n",
        "        if action == 'block_ip':\n",
        "            print(f\"[IPS] Blocking IP {ctx.get('src_ip')}\")\n",
        "        elif action == 'isolate_device':\n",
        "            print(f\"[IPS] Isolating device {ctx.get('dst_ip')}\")\n",
        "        elif action == 'notify_admin':\n",
        "            print(\"[IPS] Notifying admin for manual intervention\")\n",
        "        else:\n",
        "            print(f\"[IPS] Unknown action: {action}\")\n",
        "\n",
        "@dataclass\n",
        "class PolicyRule:\n",
        "    label: str\n",
        "    actions: list\n",
        "\n",
        "class PolicyEngine:\n",
        "    def __init__(self, rules: list, executor: ActionExecutor):\n",
        "        self.rules = rules\n",
        "        self.executor = executor\n",
        "    def evaluate(self, label: str, ctx: Dict[str, Any]):\n",
        "        for rule in self.rules:\n",
        "            if rule.label == label:\n",
        "                for a in rule.actions:\n",
        "                    self.executor.execute(a, ctx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-MCE-j6zyKd"
      },
      "source": [
        "## 5) IPS Runtime (inference + policies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ChlA8cWOzyKd"
      },
      "outputs": [],
      "source": [
        "class IPSRuntime:\n",
        "    def __init__(self, artifacts_dir='artifacts'):\n",
        "        self.model = keras.models.load_model(os.path.join(artifacts_dir, 'model.h5'))\n",
        "        self.preproc = joblib.load(os.path.join(artifacts_dir, 'preproc.pkl'))\n",
        "        self.classes = joblib.load(os.path.join(artifacts_dir, 'classes.pkl'))\n",
        "        rules = [\n",
        "            PolicyRule('normal', []),\n",
        "            PolicyRule('neptune', ['block_ip','notify_admin']),\n",
        "            PolicyRule('smurf', ['isolate_device','notify_admin'])\n",
        "        ]\n",
        "        self.engine = PolicyEngine(rules, ActionExecutor())\n",
        "    def handle_record(self, record: dict):\n",
        "        df = pd.DataFrame([record])\n",
        "        X = self.preproc.transform(df)\n",
        "        probs = self.model.predict(X)\n",
        "        idx = np.argmax(probs, axis=1)[0]\n",
        "        label = self.classes[idx]\n",
        "        ctx = record\n",
        "        self.engine.evaluate(label, ctx)\n",
        "        return label, probs[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-RSwrQh0vtl",
        "outputId": "2b2a2d73-83b4-4c8a-9403-39e186ecb446"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-07 20:16:57--  http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\n",
            "Resolving kdd.ics.uci.edu (kdd.ics.uci.edu)... 128.195.1.94\n",
            "Connecting to kdd.ics.uci.edu (kdd.ics.uci.edu)|128.195.1.94|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2144903 (2.0M) [application/x-gzip]\n",
            "Saving to: ‘kddcup.data_10_percent.gz’\n",
            "\n",
            "kddcup.data_10_perc 100%[===================>]   2.04M  1.92MB/s    in 1.1s    \n",
            "\n",
            "2025-09-07 20:16:58 (1.92 MB/s) - ‘kddcup.data_10_percent.gz’ saved [2144903/2144903]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_save(\"kddcup.data_10_percent.gz\", out_dir=\"artifacts\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czEVuwNu00nd",
        "outputId": "bc267091-b96d-484b-f643-bf071b1f92b1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.9651 - loss: 0.1861 - val_accuracy: 0.9987 - val_loss: 0.0051\n",
            "Epoch 2/5\n",
            "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9986 - loss: 0.0061 - val_accuracy: 0.9985 - val_loss: 0.0054\n",
            "Epoch 3/5\n",
            "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 0.0047 - val_accuracy: 0.9994 - val_loss: 0.0023\n",
            "Epoch 4/5\n",
            "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 0.9993 - val_loss: 0.0029\n",
            "Epoch 5/5\n",
            "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.9994 - val_loss: 0.0022\n",
            "\u001b[1m3088/3088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       430\n",
            "           1       1.00      0.40      0.57         5\n",
            "           3       1.00      1.00      1.00        11\n",
            "           4       0.50      0.50      0.50         2\n",
            "           5       0.99      0.98      0.99       241\n",
            "           6       1.00      0.80      0.89         5\n",
            "           7       0.00      0.00      0.00         1\n",
            "           9       1.00      1.00      1.00     21280\n",
            "          10       0.88      0.97      0.92        36\n",
            "          11       1.00      1.00      1.00     19550\n",
            "          12       0.00      0.00      0.00         3\n",
            "          13       0.00      0.00      0.00         1\n",
            "          14       0.98      1.00      0.99        58\n",
            "          15       1.00      0.98      0.99       239\n",
            "          16       0.00      0.00      0.00         1\n",
            "          17       1.00      0.98      0.99       306\n",
            "          18       1.00      1.00      1.00     56207\n",
            "          20       1.00      1.00      1.00       199\n",
            "          21       0.94      0.94      0.94       227\n",
            "          22       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00     98805\n",
            "   macro avg       0.76      0.73      0.74     98805\n",
            "weighted avg       1.00      1.00      1.00     98805\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runtime = IPSRuntime(artifacts_dir=\"artifacts\")\n",
        "sample_record = {\n",
        "    'duration': 0, 'protocol_type': 'tcp', 'service': 'http', 'flag': 'SF',\n",
        "    'src_bytes': 181, 'dst_bytes': 5450, 'land': 0, 'wrong_fragment': 0, 'urgent': 0,\n",
        "    'hot': 0, 'num_failed_logins': 0, 'logged_in': 1, 'num_compromised': 0,\n",
        "    'root_shell': 0, 'su_attempted': 0, 'num_root': 0, 'num_file_creations': 0,\n",
        "    'num_shells': 0, 'num_access_files': 0, 'num_outbound_cmds': 0,\n",
        "    'is_host_login': 0, 'is_guest_login': 0, 'count': 9, 'srv_count': 9,\n",
        "    'serror_rate': 0.0, 'srv_serror_rate': 0.0, 'rerror_rate': 0.0, 'srv_rerror_rate': 0.0,\n",
        "    'same_srv_rate': 1.0, 'diff_srv_rate': 0.0, 'srv_diff_host_rate': 0.0,\n",
        "    'dst_host_count': 9, 'dst_host_srv_count': 9, 'dst_host_same_srv_rate': 1.0,\n",
        "    'dst_host_diff_srv_rate': 0.0, 'dst_host_same_src_port_rate': 1.0,\n",
        "    'dst_host_srv_diff_host_rate': 0.0, 'dst_host_serror_rate': 0.0,\n",
        "    'dst_host_srv_serror_rate': 0.0, 'dst_host_rerror_rate': 0.0,\n",
        "    'dst_host_srv_rerror_rate': 0.0,\n",
        "    'label': 'normal',\n",
        "    'src_ip': '192.168.0.10', 'dst_ip': '192.168.0.1'\n",
        "}\n",
        "result = runtime.handle_record(sample_record)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSX4J8Cn1nsN",
        "outputId": "172f977e-e9a1-4bc7-9213-b240a1609dad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
            "('normal.', array([1.6157428e-04, 5.8729274e-05, 3.1972999e-05, 9.0236972e-06,\n",
            "       2.7071647e-07, 2.3776761e-04, 7.9997574e-07, 3.0858380e-05,\n",
            "       8.7482993e-05, 3.7992669e-07, 3.5694422e-05, 9.9817204e-01,\n",
            "       1.6509039e-08, 2.3334327e-05, 2.4985255e-07, 5.2901833e-06,\n",
            "       4.2473513e-04, 7.7998957e-05, 3.6847032e-06, 3.6719994e-05,\n",
            "       2.8884259e-07, 5.6375877e-04, 3.7312053e-05], dtype=float32))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}